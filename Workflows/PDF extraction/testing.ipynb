{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1670b743",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "224364ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Characters extracted: 14\n",
      "\n",
      "✅ Preview :\n",
      "\n",
      "--- PAGE 1 ---\n"
     ]
    }
   ],
   "source": [
    "from pypdf import PdfReader\n",
    "\n",
    "def extract_pdf_text(pdf_path: str) -> str:\n",
    "    reader = PdfReader(pdf_path)\n",
    "    all_pages = []\n",
    "    for i, page in enumerate(reader.pages):\n",
    "        txt = page.extract_text() or \"\"\n",
    "        all_pages.append(f\"\\n\\n--- PAGE {i+1} ---\\n{txt}\")\n",
    "    return \"\".join(all_pages).strip()\n",
    "\n",
    "# ---- Use it ----\n",
    "pdf_path = r\"C:\\Users\\harsh.raj\\OneDrive - Aster DM Healthcare\\Codes\\LangGraph\\Practical LangGraph\\Workflows\\PDF extraction\\sample Rx 2.pdf\"  # change to your file path\n",
    "text = extract_pdf_text(pdf_path)\n",
    "\n",
    "print(\"✅ Characters extracted:\", len(text))\n",
    "print(\"\\n✅ Preview :\\n\")\n",
    "print(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ce56afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install pymupdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "215015ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pages: 1\n",
      "Total extracted text chars: 0\n",
      "Total embedded images: 6\n"
     ]
    }
   ],
   "source": [
    "import fitz\n",
    "\n",
    "def pdf_diagnose(pdf_path: str):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    total_text = 0\n",
    "    total_images = 0\n",
    "    for page in doc:\n",
    "        total_text += len(page.get_text(\"text\") or \"\")\n",
    "        total_images += len(page.get_images(full=True))\n",
    "    print(\"Pages:\", len(doc))\n",
    "    print(\"Total extracted text chars:\", total_text)\n",
    "    print(\"Total embedded images:\", total_images)\n",
    "\n",
    "pdf_diagnose(pdf_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "79360c75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pdf2image in c:\\users\\administrator\\anaconda3\\envs\\langchain311\\lib\\site-packages (1.17.0)\n",
      "Requirement already satisfied: pytesseract in c:\\users\\administrator\\anaconda3\\envs\\langchain311\\lib\\site-packages (0.3.13)\n",
      "Requirement already satisfied: pillow in c:\\users\\administrator\\anaconda3\\envs\\langchain311\\lib\\site-packages (12.1.0)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\administrator\\anaconda3\\envs\\langchain311\\lib\\site-packages (from pytesseract) (24.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install pdf2image pytesseract pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b563735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-community in c:\\users\\harsh.raj\\onedrive - aster dm healthcare\\codes\\langgraph\\practical langgraph\\myenv\\lib\\site-packages (0.4.1)\n",
      "Requirement already satisfied: langchain-ollama in c:\\users\\harsh.raj\\onedrive - aster dm healthcare\\codes\\langgraph\\practical langgraph\\myenv\\lib\\site-packages (1.0.1)\n",
      "Requirement already satisfied: pymupdf in c:\\users\\harsh.raj\\onedrive - aster dm healthcare\\codes\\langgraph\\practical langgraph\\myenv\\lib\\site-packages (1.26.7)\n",
      "Requirement already satisfied: langchain-core in c:\\users\\harsh.raj\\onedrive - aster dm healthcare\\codes\\langgraph\\practical langgraph\\myenv\\lib\\site-packages (1.2.6)\n",
      "Requirement already satisfied: langchain-classic<2.0.0,>=1.0.0 in c:\\users\\harsh.raj\\onedrive - aster dm healthcare\\codes\\langgraph\\practical langgraph\\myenv\\lib\\site-packages (from langchain-community) (1.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in c:\\users\\harsh.raj\\onedrive - aster dm healthcare\\codes\\langgraph\\practical langgraph\\myenv\\lib\\site-packages (from langchain-community) (2.0.45)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.32.5 in c:\\users\\harsh.raj\\onedrive - aster dm healthcare\\codes\\langgraph\\practical langgraph\\myenv\\lib\\site-packages (from langchain-community) (2.32.5)\n",
      "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in c:\\users\\harsh.raj\\onedrive - aster dm healthcare\\codes\\langgraph\\practical langgraph\\myenv\\lib\\site-packages (from langchain-community) (6.0.3)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\harsh.raj\\onedrive - aster dm healthcare\\codes\\langgraph\\practical langgraph\\myenv\\lib\\site-packages (from langchain-community) (3.13.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\harsh.raj\\onedrive - aster dm healthcare\\codes\\langgraph\\practical langgraph\\myenv\\lib\\site-packages (from langchain-community) (9.1.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in c:\\users\\harsh.raj\\onedrive - aster dm healthcare\\codes\\langgraph\\practical langgraph\\myenv\\lib\\site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in c:\\users\\harsh.raj\\onedrive - aster dm healthcare\\codes\\langgraph\\practical langgraph\\myenv\\lib\\site-packages (from langchain-community) (2.12.0)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in c:\\users\\harsh.raj\\onedrive - aster dm healthcare\\codes\\langgraph\\practical langgraph\\myenv\\lib\\site-packages (from langchain-community) (0.6.0)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\users\\harsh.raj\\onedrive - aster dm healthcare\\codes\\langgraph\\practical langgraph\\myenv\\lib\\site-packages (from langchain-community) (0.4.3)\n",
      "Requirement already satisfied: numpy>=1.26.2 in c:\\users\\harsh.raj\\onedrive - aster dm healthcare\\codes\\langgraph\\practical langgraph\\myenv\\lib\\site-packages (from langchain-community) (2.4.0)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\users\\harsh.raj\\onedrive - aster dm healthcare\\codes\\langgraph\\practical langgraph\\myenv\\lib\\site-packages (from langchain-core) (1.33)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in c:\\users\\harsh.raj\\onedrive - aster dm healthcare\\codes\\langgraph\\practical langgraph\\myenv\\lib\\site-packages (from langchain-core) (25.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\harsh.raj\\onedrive - aster dm healthcare\\codes\\langgraph\\practical langgraph\\myenv\\lib\\site-packages (from langchain-core) (2.12.5)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in c:\\users\\harsh.raj\\onedrive - aster dm healthcare\\codes\\langgraph\\practical langgraph\\myenv\\lib\\site-packages (from langchain-core) (4.15.0)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in c:\\users\\harsh.raj\\onedrive - aster dm healthcare\\codes\\langgraph\\practical langgraph\\myenv\\lib\\site-packages (from langchain-core) (0.12.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\harsh.raj\\onedrive - aster dm healthcare\\codes\\langgraph\\practical langgraph\\myenv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\harsh.raj\\onedrive - aster dm healthcare\\codes\\langgraph\\practical langgraph\\myenv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\harsh.raj\\onedrive - aster dm healthcare\\codes\\langgraph\\practical langgraph\\myenv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\harsh.raj\\onedrive - aster dm healthcare\\codes\\langgraph\\practical langgraph\\myenv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\harsh.raj\\onedrive - aster dm healthcare\\codes\\langgraph\\practical langgraph\\myenv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\harsh.raj\\onedrive - aster dm healthcare\\codes\\langgraph\\practical langgraph\\myenv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\harsh.raj\\onedrive - aster dm healthcare\\codes\\langgraph\\practical langgraph\\myenv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.22.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\harsh.raj\\onedrive - aster dm healthcare\\codes\\langgraph\\practical langgraph\\myenv\\lib\\site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (3.26.2)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\harsh.raj\\onedrive - aster dm healthcare\\codes\\langgraph\\practical langgraph\\myenv\\lib\\site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\harsh.raj\\onedrive - aster dm healthcare\\codes\\langgraph\\practical langgraph\\myenv\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core) (3.0.0)\n",
      "Requirement already satisfied: langchain-text-splitters<2.0.0,>=1.1.0 in c:\\users\\harsh.raj\\onedrive - aster dm healthcare\\codes\\langgraph\\practical langgraph\\myenv\\lib\\site-packages (from langchain-classic<2.0.0,>=1.0.0->langchain-community) (1.1.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\harsh.raj\\onedrive - aster dm healthcare\\codes\\langgraph\\practical langgraph\\myenv\\lib\\site-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in c:\\users\\harsh.raj\\onedrive - aster dm healthcare\\codes\\langgraph\\practical langgraph\\myenv\\lib\\site-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (3.11.5)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\harsh.raj\\onedrive - aster dm healthcare\\codes\\langgraph\\practical langgraph\\myenv\\lib\\site-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\harsh.raj\\onedrive - aster dm healthcare\\codes\\langgraph\\practical langgraph\\myenv\\lib\\site-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.25.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\harsh.raj\\onedrive - aster dm healthcare\\codes\\langgraph\\practical langgraph\\myenv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (4.12.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\harsh.raj\\onedrive - aster dm healthcare\\codes\\langgraph\\practical langgraph\\myenv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\harsh.raj\\onedrive - aster dm healthcare\\codes\\langgraph\\practical langgraph\\myenv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\harsh.raj\\onedrive - aster dm healthcare\\codes\\langgraph\\practical langgraph\\myenv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\harsh.raj\\onedrive - aster dm healthcare\\codes\\langgraph\\practical langgraph\\myenv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\harsh.raj\\onedrive - aster dm healthcare\\codes\\langgraph\\practical langgraph\\myenv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\harsh.raj\\onedrive - aster dm healthcare\\codes\\langgraph\\practical langgraph\\myenv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\harsh.raj\\onedrive - aster dm healthcare\\codes\\langgraph\\practical langgraph\\myenv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core) (0.4.2)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\harsh.raj\\onedrive - aster dm healthcare\\codes\\langgraph\\practical langgraph\\myenv\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.2.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\harsh.raj\\onedrive - aster dm healthcare\\codes\\langgraph\\practical langgraph\\myenv\\lib\\site-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\harsh.raj\\onedrive - aster dm healthcare\\codes\\langgraph\\practical langgraph\\myenv\\lib\\site-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2.6.2)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\harsh.raj\\onedrive - aster dm healthcare\\codes\\langgraph\\practical langgraph\\myenv\\lib\\site-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community) (3.3.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\harsh.raj\\onedrive - aster dm healthcare\\codes\\langgraph\\practical langgraph\\myenv\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community) (1.1.0)\n",
      "Requirement already satisfied: ollama<1.0.0,>=0.6.0 in c:\\users\\harsh.raj\\onedrive - aster dm healthcare\\codes\\langgraph\\practical langgraph\\myenv\\lib\\site-packages (from langchain-ollama) (0.6.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain-community langchain-ollama pymupdf langchain-core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a02d07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: No text extracted! The PDF might be an image or empty.\n",
      "Extracting structured data...\n",
      "{\n",
      "    \"patient_name\": null,\n",
      "    \"doctor_name\": null,\n",
      "    \"diagnosis_codes\": [],\n",
      "    \"medicines\": []\n",
      "}\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import json\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 1. Setup the Model\n",
    "llm = ChatOllama(\n",
    "    model=\"llama3.2\",\n",
    "    temperature=0,  # Keep strict\n",
    "    format=\"json\" \n",
    ")\n",
    "\n",
    "# 2. Load the PDF\n",
    "pdf_path1 = r\"C:\\Users\\harsh.raj\\OneDrive - Aster DM Healthcare\\Codes\\LangGraph\\Practical LangGraph\\Workflows\\PDF extraction\\sample Rx 2.pdf\"  \n",
    "loader = PyMuPDFLoader(pdf_path) \n",
    "docs = loader.load()\n",
    "raw_text = \"\\n\".join([doc.page_content for doc in docs])\n",
    "\n",
    "# --- DEBUGGING CHECK ---\n",
    "if not raw_text.strip():\n",
    "    print(\"ERROR: No text extracted! The PDF might be an image or empty.\")\n",
    "    exit()\n",
    "else:\n",
    "    print(f\"Success: Extracted {len(raw_text)} characters.\")\n",
    "# -----------------------\n",
    "\n",
    "# 3. Create a Stronger Prompt\n",
    "prompt_template = \"\"\"\n",
    "You are a medical data extraction assistant. \n",
    "Your task is to extract specific information from the provided Prescription Text below.\n",
    "\n",
    "### STRICT RULES:\n",
    "1. Extract data ONLY from the \"Prescription Text\" section below.\n",
    "2. Do NOT invent or hallucinate names (like \"John Doe\"). Use the actual names found in the text.\n",
    "3. If a field is missing in the text, return null or an empty string.\n",
    "4. Return the output as valid JSON.\n",
    "\n",
    "### Prescription Text:\n",
    "{text}\n",
    "\n",
    "### Desired JSON Structure:\n",
    "{{\n",
    "  \"patient_name\": \"string\",\n",
    "  \"doctor_name\": \"string\",\n",
    "  \"diagnosis_codes\": [\"string\", \"string\"],\n",
    "  \"medicines\": [\n",
    "    {{\n",
    "      \"name\": \"string\",\n",
    "      \"dosage_instruction\": \"string\",\n",
    "      \"duration\": \"string\"\n",
    "    }}\n",
    "  ]\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "# Note: We use {{ double braces }} to escape them in f-strings or prompt templates \n",
    "# where we don't want Python to interpret them as variables.\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=prompt_template,\n",
    "    input_variables=[\"text\"]\n",
    ")\n",
    "\n",
    "# 4. Build the Chain\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "# 5. Run Extraction\n",
    "try:\n",
    "    print(\"Extracting structured data...\")\n",
    "    result = chain.invoke({\"text\": raw_text})\n",
    "    \n",
    "    # Parse and Print\n",
    "    data = json.loads(result)\n",
    "    print(json.dumps(data, indent=4))\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "065c441c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting structured data...\n",
      "{\n",
      "    \"patient_name\": \"John Doe\",\n",
      "    \"doctor_name\": \"Dr. Jane Smith\",\n",
      "    \"diagnosis_codes\": [\n",
      "        \"I10\",\n",
      "        \"I11\"\n",
      "    ],\n",
      "    \"medicines\": [\n",
      "        {\n",
      "            \"name\": \"Aspirin\",\n",
      "            \"dosage_instruction\": \"2 tablets daily\",\n",
      "            \"duration\": \"for 3 months\"\n",
      "        },\n",
      "        {\n",
      "            \"name\": \"Lisinopril\",\n",
      "            \"dosage_instruction\": \"1 tablet once daily\",\n",
      "            \"duration\": \"for 6 months\"\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# 1. Load the PDF\n",
    "pdf_path1 = r\"C:\\Users\\harsh.raj\\OneDrive - Aster DM Healthcare\\Codes\\LangGraph\\Practical LangGraph\\Workflows\\PDF extraction\\sample Rx 1.pdf\"  \n",
    "import json\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 1. Setup the Model\n",
    "llm = ChatOllama(\n",
    "    model=\"llama3.2\",\n",
    "    temperature=0,  # Temperature 0 is critical for data extraction\n",
    "    format=\"json\"   # Llama 3.2 supports native JSON mode\n",
    ")\n",
    "\n",
    "# 2. Load the PDF\n",
    "# PyMuPDF is the best choice here because it reads the hidden text layers \n",
    "# in your digital PDF even if the layout is messy.\n",
    "loader = PyMuPDFLoader(pdf_path1) \n",
    "docs = loader.load()\n",
    "raw_text = \"\\n\".join([doc.page_content for doc in docs])\n",
    "\n",
    "# 3. Create a Targeted Prompt\n",
    "# We ask the LLM to ignore the layout noise and find specific entities.\n",
    "prompt_template = \"\"\"\n",
    "You are a medical data assistant. Extract details from the following prescription text.\n",
    "Return ONLY a valid JSON object. Do not add any conversational text.\n",
    "\n",
    "Extract these fields:\n",
    "- patient_name\n",
    "- doctor_name\n",
    "- diagnosis_codes (as a list)\n",
    "- medicines (as a list of objects with fields: name, dosage_instruction, duration)\n",
    "\n",
    "Prescription Text:\n",
    "{text}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=prompt_template,\n",
    "    input_variables=[\"text\"]\n",
    ")\n",
    "\n",
    "# 4. Build the Chain\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "# 5. Run Extraction\n",
    "try:\n",
    "    print(\"Extracting structured data...\")\n",
    "    result = chain.invoke({\"text\": raw_text})\n",
    "    \n",
    "    # Parse the string result into a real Python dictionary\n",
    "    data = json.loads(result)\n",
    "    \n",
    "    # Print pretty JSON\n",
    "    print(json.dumps(data, indent=4))\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06d6ea06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pdfplumber\n",
      "  Downloading pdfplumber-0.11.9-py3-none-any.whl.metadata (43 kB)\n",
      "Collecting pdfminer.six==20251230 (from pdfplumber)\n",
      "  Downloading pdfminer_six-20251230-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: Pillow>=9.1 in c:\\users\\harsh.raj\\onedrive - aster dm healthcare\\codes\\langgraph\\practical langgraph\\myenv\\lib\\site-packages (from pdfplumber) (12.1.0)\n",
      "Collecting pypdfium2>=4.18.0 (from pdfplumber)\n",
      "  Downloading pypdfium2-5.2.0-py3-none-win_amd64.whl.metadata (67 kB)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in c:\\users\\harsh.raj\\onedrive - aster dm healthcare\\codes\\langgraph\\practical langgraph\\myenv\\lib\\site-packages (from pdfminer.six==20251230->pdfplumber) (3.4.4)\n",
      "Collecting cryptography>=36.0.0 (from pdfminer.six==20251230->pdfplumber)\n",
      "  Downloading cryptography-46.0.3-cp311-abi3-win_amd64.whl.metadata (5.7 kB)\n",
      "Collecting cffi>=2.0.0 (from cryptography>=36.0.0->pdfminer.six==20251230->pdfplumber)\n",
      "  Downloading cffi-2.0.0-cp312-cp312-win_amd64.whl.metadata (2.6 kB)\n",
      "Collecting pycparser (from cffi>=2.0.0->cryptography>=36.0.0->pdfminer.six==20251230->pdfplumber)\n",
      "  Downloading pycparser-2.23-py3-none-any.whl.metadata (993 bytes)\n",
      "Downloading pdfplumber-0.11.9-py3-none-any.whl (60 kB)\n",
      "Downloading pdfminer_six-20251230-py3-none-any.whl (6.6 MB)\n",
      "   ---------------------------------------- 0.0/6.6 MB ? eta -:--:--\n",
      "   -------------------- ------------------- 3.4/6.6 MB 16.8 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 5.8/6.6 MB 14.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.6/6.6 MB 10.7 MB/s  0:00:00\n",
      "Downloading cryptography-46.0.3-cp311-abi3-win_amd64.whl (3.5 MB)\n",
      "   ---------------------------------------- 0.0/3.5 MB ? eta -:--:--\n",
      "   -------------------------- ------------- 2.4/3.5 MB 16.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.5/3.5 MB 8.3 MB/s  0:00:00\n",
      "Downloading cffi-2.0.0-cp312-cp312-win_amd64.whl (183 kB)\n",
      "Downloading pypdfium2-5.2.0-py3-none-win_amd64.whl (3.1 MB)\n",
      "   ---------------------------------------- 0.0/3.1 MB ? eta -:--:--\n",
      "   ------------------------------------- -- 2.9/3.1 MB 12.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.1/3.1 MB 9.1 MB/s  0:00:00\n",
      "Downloading pycparser-2.23-py3-none-any.whl (118 kB)\n",
      "Installing collected packages: pypdfium2, pycparser, cffi, cryptography, pdfminer.six, pdfplumber\n",
      "\n",
      "   ---------------------------------------- 0/6 [pypdfium2]\n",
      "   ---------------------------------------- 0/6 [pypdfium2]\n",
      "   ---------------------------------------- 0/6 [pypdfium2]\n",
      "   ---------------------------------------- 0/6 [pypdfium2]\n",
      "   ------ --------------------------------- 1/6 [pycparser]\n",
      "   ------------- -------------------------- 2/6 [cffi]\n",
      "   -------------------- ------------------- 3/6 [cryptography]\n",
      "   -------------------- ------------------- 3/6 [cryptography]\n",
      "   -------------------- ------------------- 3/6 [cryptography]\n",
      "   -------------------- ------------------- 3/6 [cryptography]\n",
      "   -------------------- ------------------- 3/6 [cryptography]\n",
      "   -------------------------- ------------- 4/6 [pdfminer.six]\n",
      "   -------------------------- ------------- 4/6 [pdfminer.six]\n",
      "   -------------------------- ------------- 4/6 [pdfminer.six]\n",
      "   --------------------------------- ------ 5/6 [pdfplumber]\n",
      "   --------------------------------- ------ 5/6 [pdfplumber]\n",
      "   ---------------------------------------- 6/6 [pdfplumber]\n",
      "\n",
      "Successfully installed cffi-2.0.0 cryptography-46.0.3 pdfminer.six-20251230 pdfplumber-0.11.9 pycparser-2.23 pypdfium2-5.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pdfplumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9911a683",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh.raj\\OneDrive - Aster DM Healthcare\\Codes\\LangGraph\\Practical LangGraph\\myenv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file: C:\\Users\\harsh.raj\\OneDrive - Aster DM Healthcare\\Codes\\LangGraph\\Practical LangGraph\\Workflows\\PDF extraction\\sample Rx 1.pdf...\n",
      "--- DEBUG: Extracted 0 characters ---\n",
      "⚠️ WARNING: Very little text found. The PDF might be scanned (image-based).\n",
      "If the text below is empty, we need to use OCR.\n",
      "--------------------\n",
      "\n",
      "--------------------\n",
      "Sending text to LLM for structuring...\n",
      "{\n",
      "    \"patient_name\": null,\n",
      "    \"doctor_name\": null,\n",
      "    \"diagnosis_codes\": [],\n",
      "    \"medicines\": []\n",
      "}\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pdfplumber\n",
    "import json\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "pdf_path = r\"C:\\Users\\harsh.raj\\OneDrive - Aster DM Healthcare\\Codes\\LangGraph\\Practical LangGraph\\Workflows\\PDF extraction\\sample Rx 1.pdf\"  \n",
    "# ---------------------\n",
    "\n",
    "# 1. Debug: Check if file exists\n",
    "if not os.path.exists(pdf_path):\n",
    "    print(f\"❌ ERROR: File not found at: {os.path.abspath(pdf_path)}\")\n",
    "    print(\"Please check the file name or provide the full path (e.g., C:/Users/Name/Downloads/sample Rx 1.pdf)\")\n",
    "    exit()\n",
    "\n",
    "# 2. Extract Text using PDFPlumber (More robust than PyMuPDF)\n",
    "print(f\"Reading file: {pdf_path}...\")\n",
    "raw_text = \"\"\n",
    "with pdfplumber.open(pdf_path) as pdf:\n",
    "    for page in pdf.pages:\n",
    "        text = page.extract_text()\n",
    "        if text:\n",
    "            raw_text += text + \"\\n\"\n",
    "\n",
    "# 3. Check what we found\n",
    "print(f\"--- DEBUG: Extracted {len(raw_text)} characters ---\")\n",
    "if len(raw_text) < 50:\n",
    "    print(\"⚠️ WARNING: Very little text found. The PDF might be scanned (image-based).\")\n",
    "    print(\"If the text below is empty, we need to use OCR.\")\n",
    "    print(\"-\" * 20)\n",
    "    print(raw_text)\n",
    "    print(\"-\" * 20)\n",
    "    if not raw_text.strip():\n",
    "        exit()\n",
    "\n",
    "# 4. Setup LLM (Only runs if text was found)\n",
    "llm = ChatOllama(\n",
    "    model=\"llama3.2\",\n",
    "    temperature=0,\n",
    "    format=\"json\" \n",
    ")\n",
    "\n",
    "# 5. Define Prompt\n",
    "prompt_template = \"\"\"\n",
    "You are a medical data assistant. Extract details from the text below.\n",
    "\n",
    "STRICT RULES:\n",
    "1. Use ONLY the provided text.\n",
    "2. If the text does not contain a name, do NOT invent \"John Doe\". Return null.\n",
    "3. Return valid JSON.\n",
    "\n",
    "TEXT:\n",
    "{text}\n",
    "\n",
    "JSON FORMAT:\n",
    "{{\n",
    "  \"patient_name\": \"string\",\n",
    "  \"doctor_name\": \"string\",\n",
    "  \"diagnosis_codes\": [\"code1\", \"code2\"],\n",
    "  \"medicines\": [\n",
    "    {{ \"name\": \"drug name\", \"dosage\": \"dosage instructions\", \"duration\": \"duration\" }}\n",
    "  ]\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=prompt_template, input_variables=[\"text\"])\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "# 6. Run Chain\n",
    "try:\n",
    "    print(\"Sending text to LLM for structuring...\")\n",
    "    result = chain.invoke({\"text\": raw_text})\n",
    "    parsed = json.loads(result)\n",
    "    print(json.dumps(parsed, indent=4))\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197a97ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv (3.12.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
