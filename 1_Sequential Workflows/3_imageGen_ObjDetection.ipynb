{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7dc0fd1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting huggingface_hub\n",
      "  Downloading huggingface_hub-1.2.3-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting pillow\n",
      "  Downloading pillow-12.1.0-cp312-cp312-win_amd64.whl.metadata (9.0 kB)\n",
      "Collecting filelock (from huggingface_hub)\n",
      "  Downloading filelock-3.20.2-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface_hub)\n",
      "  Using cached fsspec-2025.12.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting hf-xet<2.0.0,>=1.2.0 (from huggingface_hub)\n",
      "  Downloading hf_xet-1.2.0-cp37-abi3-win_amd64.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\harsh.raj\\onedrive - aster dm healthcare\\codes\\langgraph\\practical langgraph\\myenv\\lib\\site-packages (from huggingface_hub) (0.28.1)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\harsh.raj\\onedrive - aster dm healthcare\\codes\\langgraph\\practical langgraph\\myenv\\lib\\site-packages (from huggingface_hub) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\harsh.raj\\onedrive - aster dm healthcare\\codes\\langgraph\\practical langgraph\\myenv\\lib\\site-packages (from huggingface_hub) (6.0.3)\n",
      "Collecting shellingham (from huggingface_hub)\n",
      "  Using cached shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\harsh.raj\\onedrive - aster dm healthcare\\codes\\langgraph\\practical langgraph\\myenv\\lib\\site-packages (from huggingface_hub) (4.67.1)\n",
      "Collecting typer-slim (from huggingface_hub)\n",
      "  Downloading typer_slim-0.21.0-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\harsh.raj\\onedrive - aster dm healthcare\\codes\\langgraph\\practical langgraph\\myenv\\lib\\site-packages (from huggingface_hub) (4.15.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\harsh.raj\\onedrive - aster dm healthcare\\codes\\langgraph\\practical langgraph\\myenv\\lib\\site-packages (from httpx<1,>=0.23.0->huggingface_hub) (4.12.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\harsh.raj\\onedrive - aster dm healthcare\\codes\\langgraph\\practical langgraph\\myenv\\lib\\site-packages (from httpx<1,>=0.23.0->huggingface_hub) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\harsh.raj\\onedrive - aster dm healthcare\\codes\\langgraph\\practical langgraph\\myenv\\lib\\site-packages (from httpx<1,>=0.23.0->huggingface_hub) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\harsh.raj\\onedrive - aster dm healthcare\\codes\\langgraph\\practical langgraph\\myenv\\lib\\site-packages (from httpx<1,>=0.23.0->huggingface_hub) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\harsh.raj\\onedrive - aster dm healthcare\\codes\\langgraph\\practical langgraph\\myenv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface_hub) (0.16.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\harsh.raj\\onedrive - aster dm healthcare\\codes\\langgraph\\practical langgraph\\myenv\\lib\\site-packages (from tqdm>=4.42.1->huggingface_hub) (0.4.6)\n",
      "Collecting click>=8.0.0 (from typer-slim->huggingface_hub)\n",
      "  Using cached click-8.3.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Downloading huggingface_hub-1.2.3-py3-none-any.whl (520 kB)\n",
      "Downloading hf_xet-1.2.0-cp37-abi3-win_amd64.whl (2.9 MB)\n",
      "   ---------------------------------------- 0.0/2.9 MB ? eta -:--:--\n",
      "   ---------------------------- ----------- 2.1/2.9 MB 14.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.9/2.9 MB 10.6 MB/s  0:00:00\n",
      "Downloading pillow-12.1.0-cp312-cp312-win_amd64.whl (7.0 MB)\n",
      "   ---------------------------------------- 0.0/7.0 MB ? eta -:--:--\n",
      "   ---------------------------------- ----- 6.0/7.0 MB 28.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 7.0/7.0 MB 19.7 MB/s  0:00:00\n",
      "Using cached fsspec-2025.12.0-py3-none-any.whl (201 kB)\n",
      "Downloading filelock-3.20.2-py3-none-any.whl (16 kB)\n",
      "Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading typer_slim-0.21.0-py3-none-any.whl (47 kB)\n",
      "Using cached click-8.3.1-py3-none-any.whl (108 kB)\n",
      "Installing collected packages: shellingham, pillow, hf-xet, fsspec, filelock, click, typer-slim, huggingface_hub\n",
      "\n",
      "   ----- ---------------------------------- 1/8 [pillow]\n",
      "   ----- ---------------------------------- 1/8 [pillow]\n",
      "   ----- ---------------------------------- 1/8 [pillow]\n",
      "   ----- ---------------------------------- 1/8 [pillow]\n",
      "   ----- ---------------------------------- 1/8 [pillow]\n",
      "   ----- ---------------------------------- 1/8 [pillow]\n",
      "   --------------- ------------------------ 3/8 [fsspec]\n",
      "   --------------- ------------------------ 3/8 [fsspec]\n",
      "   --------------- ------------------------ 3/8 [fsspec]\n",
      "   ------------------------- -------------- 5/8 [click]\n",
      "   ----------------------------------- ---- 7/8 [huggingface_hub]\n",
      "   ----------------------------------- ---- 7/8 [huggingface_hub]\n",
      "   ----------------------------------- ---- 7/8 [huggingface_hub]\n",
      "   ----------------------------------- ---- 7/8 [huggingface_hub]\n",
      "   ----------------------------------- ---- 7/8 [huggingface_hub]\n",
      "   ----------------------------------- ---- 7/8 [huggingface_hub]\n",
      "   ---------------------------------------- 8/8 [huggingface_hub]\n",
      "\n",
      "Successfully installed click-8.3.1 filelock-3.20.2 fsspec-2025.12.0 hf-xet-1.2.0 huggingface_hub-1.2.3 pillow-12.1.0 shellingham-1.5.4 typer-slim-0.21.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -U huggingface_hub pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b8c02a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh.raj\\OneDrive - Aster DM Healthcare\\Codes\\LangGraph\\Practical LangGraph\\myenv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# CELL 1 ‚Äî Imports + Config (HF + Ollama)\n",
    "\n",
    "import os, time, json\n",
    "import requests\n",
    "\n",
    "from typing import TypedDict, List, Literal\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "from IPython.display import display, Markdown, Image\n",
    "from pprint import pprint\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from huggingface_hub import InferenceClient\n",
    "\n",
    "# ---- Hugging Face token (set it in env as HF_TOKEN) ----\n",
    "HF_TOKEN = os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")\n",
    "if not HF_TOKEN:\n",
    "    raise ValueError(\"HF_TOKEN not found in environment. Set it before running the notebook.\")\n",
    "\n",
    "HF_HEADERS = {\"Authorization\": f\"Bearer {HF_TOKEN}\"}\n",
    "\n",
    "# Uses your existing HF_TOKEN / HUGGINGFACEHUB_API_TOKEN from .env\n",
    "hf_client = InferenceClient(\n",
    "    provider=\"fal-ai\",          # text-to-image is supported on fal-ai\n",
    "    api_key=HF_TOKEN,\n",
    ")\n",
    "\n",
    "# ---- HF Inference endpoints ----\n",
    "# Text-to-image model (choose one you have access to / that fits your usage)\n",
    "HF_T2I_MODEL = \"stabilityai/stable-diffusion-2-1\"\n",
    "HF_T2I_URL   = f\"https://api-inference.huggingface.co/models/{HF_T2I_MODEL}\"\n",
    "\n",
    "# Object detection model (DETR is a solid default)\n",
    "HF_OD_MODEL  = \"facebook/detr-resnet-50\"\n",
    "HF_OD_URL   = f\"https://api-inference.huggingface.co/models/{HF_OD_MODEL}\"\n",
    "\n",
    "# ---- Output folder ----\n",
    "OUTPUT_DIR = \"outputs\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# ---- Ollama models ----\n",
    "TEXT_MODEL  = \"llama3.2\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a89d0b42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh.raj\\OneDrive - Aster DM Healthcare\\Codes\\LangGraph\\Practical LangGraph\\myenv\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:270: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Loading pipeline components...:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:19<00:24,  6.13s/it]`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Loading pipeline components...: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:38<00:00,  5.47s/it]\n"
     ]
    }
   ],
   "source": [
    "# CELL 2 ‚Äî State + Nodes (Prompt ‚Üí Local SDXL ‚Üí Object Detection ‚Üí Ollama Summary)\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from diffusers import DiffusionPipeline\n",
    "from typing import TypedDict, List\n",
    "\n",
    "# ---- Load Diffusion Model ONCE (important) ----\n",
    "# NOTE: You can switch device_map to \"cuda\" if GPU is available\n",
    "pipe = DiffusionPipeline.from_pretrained(\n",
    "    \"stabilityai/stable-diffusion-xl-base-1.0\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"cpu\"\n",
    ")\n",
    "\n",
    "pipe.enable_attention_slicing()  # reduces memory footprint\n",
    "\n",
    "# ---- Workflow State ----\n",
    "class WorkflowState(TypedDict, total=False):\n",
    "    topic: str\n",
    "    image_prompt: str\n",
    "    image_path: str\n",
    "    objects: List[str]\n",
    "    summary: str\n",
    "\n",
    "# ---- Ollama LLMs ----\n",
    "llm_prompt  = ChatOllama(model=TEXT_MODEL, temperature=0.5)\n",
    "llm_summary = ChatOllama(model=TEXT_MODEL, temperature=0.2)\n",
    "\n",
    "# -------------------------\n",
    "# Node 1: Topic ‚Üí Image Prompt\n",
    "# -------------------------\n",
    "def generate_image_prompt(state: WorkflowState) -> WorkflowState:\n",
    "    topic = state[\"topic\"]\n",
    "\n",
    "    sys = (\n",
    "        \"You are an expert prompt engineer for photorealistic image generation. \"\n",
    "        \"Return ONLY one final prompt. No explanations.\"\n",
    "    )\n",
    "    user = (\n",
    "        f\"Topic: {topic}\\n\\n\"\n",
    "        \"Write one detailed photorealistic prompt including:\\n\"\n",
    "        \"- subject and environment\\n\"\n",
    "        \"- lighting and mood\\n\"\n",
    "        \"- camera / lens style\\n\"\n",
    "        \"- ultra-detailed, cinematic realism\\n\"\n",
    "        \"Avoid: text, watermarks, logos.\"\n",
    "    )\n",
    "\n",
    "    resp = llm_prompt.invoke([(\"system\", sys), (\"user\", user)])\n",
    "    return {\"image_prompt\": resp.content.strip()}\n",
    "\n",
    "# -------------------------\n",
    "# Node 2: Prompt ‚Üí Image (LOCAL SDXL)\n",
    "# -------------------------\n",
    "def generate_image(state: WorkflowState) -> WorkflowState:\n",
    "    prompt = state[\"image_prompt\"]\n",
    "    out_path = os.path.join(OUTPUT_DIR, \"generated.png\")\n",
    "\n",
    "    image = pipe(prompt).images[0]\n",
    "    image.save(out_path)\n",
    "\n",
    "    return {\"image_path\": out_path}\n",
    "\n",
    "# -------------------------\n",
    "# Node 3: Image ‚Üí Object Detection (HF DETR ‚Äî FREE)\n",
    "# -------------------------\n",
    "def detect_objects(state: WorkflowState) -> WorkflowState:\n",
    "    image_path = state[\"image_path\"]\n",
    "\n",
    "    with open(image_path, \"rb\") as f:\n",
    "        img_bytes = f.read()\n",
    "\n",
    "    r = requests.post(\n",
    "        HF_OD_URL,\n",
    "        headers=HF_HEADERS,\n",
    "        data=img_bytes,\n",
    "        timeout=120\n",
    "    )\n",
    "\n",
    "    r.raise_for_status()\n",
    "    detections = r.json()\n",
    "\n",
    "    labels = []\n",
    "    for d in detections:\n",
    "        label = d.get(\"label\")\n",
    "        if label:\n",
    "            labels.append(label)\n",
    "\n",
    "    # De-duplicate while preserving order\n",
    "    seen, unique = set(), []\n",
    "    for l in labels:\n",
    "        if l not in seen:\n",
    "            seen.add(l)\n",
    "            unique.append(l)\n",
    "\n",
    "    return {\"objects\": unique}\n",
    "\n",
    "# -------------------------\n",
    "# Node 4: Objects ‚Üí Final Summary\n",
    "# -------------------------\n",
    "def summarize(state: WorkflowState) -> WorkflowState:\n",
    "    topic = state[\"topic\"]\n",
    "    objects = state.get(\"objects\", [])\n",
    "\n",
    "    prompt = (\n",
    "        f\"Topic: {topic}\\n\"\n",
    "        f\"Detected objects: {objects}\\n\\n\"\n",
    "        \"Write a crisp final summary in 5 bullets:\\n\"\n",
    "        \"- what the image likely depicts\\n\"\n",
    "        \"- key objects and their roles\\n\"\n",
    "        \"- scene and atmosphere\\n\"\n",
    "        \"- notable visual details\\n\"\n",
    "    )\n",
    "\n",
    "    resp = llm_summary.invoke(prompt)\n",
    "    return {\"summary\": resp.content.strip()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5943084b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 3 ‚Äî Graph & Edges (no notebook-specific tricks here)\n",
    "\n",
    "graph = StateGraph(WorkflowState)\n",
    "\n",
    "graph.add_node(\"generate_image_prompt\", generate_image_prompt)\n",
    "graph.add_node(\"generate_image\", generate_image)\n",
    "graph.add_node(\"detect_objects\", detect_objects)\n",
    "graph.add_node(\"summarize\", summarize)\n",
    "\n",
    "graph.add_edge(START, \"generate_image_prompt\")\n",
    "graph.add_edge(\"generate_image_prompt\", \"generate_image\")\n",
    "graph.add_edge(\"generate_image\", \"detect_objects\")\n",
    "graph.add_edge(\"detect_objects\", \"summarize\")\n",
    "graph.add_edge(\"summarize\", END)\n",
    "\n",
    "workflow = graph.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6171d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 4 ‚Äî Run + Pretty Output + Checkpoints (ipynb-friendly)\n",
    "\n",
    "def checkpoint(msg: str):\n",
    "    display(Markdown(f\"‚úÖ **Checkpoint:** {msg}\"))\n",
    "\n",
    "def show_output(initial_state: dict, final_state: dict):\n",
    "    checkpoint(\"Rendering output started\")\n",
    "\n",
    "    display(Markdown(\"## üü¶ Input\"))\n",
    "    display(Markdown(f\"**Topic:** `{initial_state.get('topic','')}`\"))\n",
    "\n",
    "    display(Markdown(\"## üñºÔ∏è Generated Image\"))\n",
    "    img_path = final_state.get(\"image_path\")\n",
    "    if img_path and os.path.exists(img_path):\n",
    "        checkpoint(\"Image found on disk ‚Äî displaying it\")\n",
    "        display(Image(filename=img_path))\n",
    "        display(Markdown(f\"Saved at: `{img_path}`\"))\n",
    "    else:\n",
    "        checkpoint(\"Image not found / not generated\")\n",
    "        display(Markdown(\"_Image not available (generation failed or file missing)._\"))\n",
    "\n",
    "    display(Markdown(\"## üß© Detected Objects\"))\n",
    "    objs = final_state.get(\"objects\", [])\n",
    "    if objs:\n",
    "        checkpoint(f\"Objects detected ‚Äî count: {len(objs)}\")\n",
    "        display(Markdown(\"\\n\".join([f\"- {o}\" for o in objs])))\n",
    "    else:\n",
    "        checkpoint(\"No objects detected (or detection node did not populate state)\")\n",
    "        display(Markdown(\"_No objects detected._\"))\n",
    "\n",
    "    display(Markdown(\"## üìù Summary\"))\n",
    "    summary = final_state.get(\"summary\", \"\")\n",
    "    if summary:\n",
    "        checkpoint(\"Summary present ‚Äî rendering it\")\n",
    "        display(Markdown(summary.replace(\"\\n\", \"  \\n\")))\n",
    "    else:\n",
    "        checkpoint(\"No summary found in final_state\")\n",
    "        display(Markdown(\"_No summary._\"))\n",
    "\n",
    "    checkpoint(\"Rendering output completed\")\n",
    "\n",
    "\n",
    "# ---- Execute with execution checkpoints ----\n",
    "checkpoint(\"About to invoke workflow\")\n",
    "\n",
    "initial_state = {\"topic\": \"Bengal tiger walking through tall grass at sunrise, golden light, shallow depth\"}\n",
    "checkpoint(\"Initial state created\")\n",
    "\n",
    "final_state = workflow.invoke(initial_state)\n",
    "\n",
    "checkpoint(\"Workflow invocation completed ‚Äî now displaying results\")\n",
    "show_output(initial_state, final_state)\n",
    "\n",
    "# Optional: also inspect raw keys/state\n",
    "checkpoint(\"Displaying raw state keys\")\n",
    "display(Markdown(\"### üîé Raw state keys\"))\n",
    "pprint(list(final_state.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b519e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv (3.12.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
